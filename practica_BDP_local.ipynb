{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VwExDgBPKbc_"
      },
      "outputs": [],
      "source": [
        "### verificar la instalación ###\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "Xw0gGtkSKd_T",
        "outputId": "ff2549e1-2a73-4b89-bcf6-ff02431d1e24"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://PcEmilio:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>whr_spark</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x201045396d0>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"whr_spark\").master(\"local[*]\").getOrCreate()\n",
        "spark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Lectura de ficheros de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RygJ2b4ANdvI"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,DoubleType\n",
        "#Leemos el cvs general de mi drive, solo los campos necesarios y con el formato necesaario\n",
        "schema_whr = StructType() \\\n",
        "      .add(\"Country name\",StringType(),True) \\\n",
        "      .add(\"year\",IntegerType(),True) \\\n",
        "      .add(\"Life Ladder\",DoubleType(),True) \\\n",
        "      .add(\"Log GDP per capita\",DoubleType(),True) \\\n",
        "      .add(\"Social support\",DoubleType(),True) \\\n",
        "      .add(\"Healthy life expectancy at birth\",DoubleType(),True) \\\n",
        "      # .add(\"Freedom to make life choices\",DoubleType(),True) \\\n",
        "      # .add(\"Generosity\",DoubleType(),True) \\\n",
        "      # .add(\"Perceptions of corruption\",DoubleType(),True) \\\n",
        "      # .add(\"Positive affect\",DoubleType(),True) \\\n",
        "      # .add(\"Negative affect\",DoubleType(),True)\n",
        "\n",
        "df_whr = spark.read.format(\"csv\") \\\n",
        "      .option(\"header\", True) \\\n",
        "      .schema(schema_whr) \\\n",
        "      .load('Datasets/world-happiness-report.csv')\n",
        "\n",
        "schema_whr21 = StructType() \\\n",
        "      .add(\"Country name\",StringType(),True) \\\n",
        "      .add(\"Regional indicator\",StringType(),True) \\\n",
        "      .add(\"Ladder score\",DoubleType(),True) \\\n",
        "      .add(\"Standard error of ladder score\",DoubleType(),True) \\\n",
        "      .add(\"upperwhisker\",DoubleType(),True) \\\n",
        "      .add(\"lowerwhisker\",DoubleType(),True) \\\n",
        "      .add(\"Logged GDP per capita\",DoubleType(),True) \\\n",
        "      .add(\"Healthy life expectancy\",DoubleType(),True) \\\n",
        "      # .add(\"Freedom to make life choices\",DoubleType(),True) \\\n",
        "      # .add(\"Generosity\",DoubleType(),True) \\\n",
        "      # .add(\"Perceptions of corruption\",DoubleType(),True) \\\n",
        "      # .add(\"Ladder score in Dystopia\",DoubleType(),True) \\\n",
        "      # .add(\"Explained by: Log GDP per capita\",DoubleType(),True) \\\n",
        "      # .add(\"Explained by: Social support\",DoubleType(),True) \\\n",
        "      # .add(\"Explained by: Healthy life expectancy\",DoubleType(),True) \\\n",
        "      # .add(\"Explained by: Freedom to make life choices\",DoubleType(),True) \\\n",
        "      # .add(\"Explained by: Generosity\",DoubleType(),True) \\\n",
        "      # .add(\"Explained by: Perceptions of corruption\",DoubleType(),True) \\\n",
        "      # .add(\"Dystopia + residual\",DoubleType(),True)\n",
        "\n",
        "df_whr2021 = spark.read.format(\"csv\") \\\n",
        "      .option(\"header\", True) \\\n",
        "      .schema(schema_whr21) \\\n",
        "      .load('Datasets/world-happiness-report-2021.csv')\n",
        "\n",
        "\n",
        "schema_countries = StructType() \\\n",
        "      .add(\"country\",StringType(),True) \\\n",
        "      .add(\"region\",StringType(),True)\n",
        "\n",
        "df_countries = spark.read.format(\"csv\") \\\n",
        "      .option(\"header\", True) \\\n",
        "      .schema(schema_countries) \\\n",
        "      .load('Datasets/list-of-countries-by-continent-2024.csv')\n",
        "# df_whr.show(2)\n",
        "# df_whr2021.show(2)\n",
        "# df_countries.show(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Limpìeza y estandarización de datos\n",
        "1. Renombrar columnas\n",
        "2. Añadir el año de los datos del 2021\n",
        "3. Union de datos, todos los años con el año 2021\n",
        "4. Join de todos los datos anuales con sus regiones(continentes)\n",
        "5. Comprobar que columnas contiene nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XtHucMfCkI6a"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "j7Ulz8dKeJoI"
      },
      "outputs": [],
      "source": [
        "# Renombrar las columnas para normalizarlas\n",
        "df_whr = df_whr.select('Country name','Life Ladder','Log GDP per capita','Healthy life expectancy at birth','year')\n",
        "df_whr = df_whr.toDF(*(\"country\", \"ladder\",\"gdp\",\"healthy\", \"year\"))\n",
        "# df_whr.show(2)\n",
        "df_whr2021 = df_whr2021.select('Country name','Ladder score','Logged GDP per capita','Healthy life expectancy')\n",
        "df_whr2021 = df_whr2021.toDF(*(\"country\", \"ladder\",\"gdp\",\"healthy\"))\n",
        "# df_whr2021.show(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8m1xAvDst9ml"
      },
      "outputs": [],
      "source": [
        "# Añadir el año de los datos en una columna\n",
        "df_whr2021 = df_whr2021.withColumn(\"year\", F.lit(2021))\n",
        "# df_whr2021.show(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dm3tgOG2trdm",
        "outputId": "cd91c8c6-1686-483f-8132-b1f590c7d25f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+------+----+-------+----+\n",
            "|    country|ladder| gdp|healthy|year|\n",
            "+-----------+------+----+-------+----+\n",
            "|Afghanistan| 3.724|7.37|   50.8|2008|\n",
            "|Afghanistan| 4.402|7.54|   51.2|2009|\n",
            "+-----------+------+----+-------+----+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Unir los dataframes ahora que tienen la misma estructura y tendremos todos los datos de todos los años\n",
        "df_whr_all = df_whr.union(df_whr2021)\n",
        "\n",
        "df_whr_all.show(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luVEQwCxP4ip",
        "outputId": "43186569-ef55-41ae-8d74-7440486c93b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+------+----+-------+----+------+\n",
            "|    country|ladder| gdp|healthy|year|region|\n",
            "+-----------+------+----+-------+----+------+\n",
            "|Afghanistan| 3.724|7.37|   50.8|2008|  Asia|\n",
            "|Afghanistan| 4.402|7.54|   51.2|2009|  Asia|\n",
            "+-----------+------+----+-------+----+------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# completar los datos del dataframe con la región\n",
        "\n",
        "df_whr_c = df_whr_all.join(df_countries,['country'],\"left\")\n",
        "df_whr_c.show(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f30LRKqrX-Fb",
        "outputId": "4a6c8b4a-a40a-4b00-8aa0-b0861c7cd17c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nulos en Region: 0\n",
            "nulos en ladder: 0\n",
            "nulos en gdp: 36\n",
            "nulos en healthy: 55\n",
            "nulos en year: 0\n"
          ]
        }
      ],
      "source": [
        "# Observar los datos si contienen nulos, para eviar errores posteriores\n",
        "print(f'nulos en Region: {df_whr_c.filter(df_whr_c.region.isNull()).count()}')\n",
        "print(f'nulos en ladder: {df_whr_c.filter(df_whr_c.ladder.isNull()).count()}')\n",
        "print(f'nulos en gdp: {df_whr_c.filter(df_whr_c.gdp.isNull()).count()}')\n",
        "print(f'nulos en healthy: {df_whr_c.filter(df_whr_c.healthy.isNull()).count()}')\n",
        "print(f'nulos en year: {df_whr_c.filter(df_whr_c.year.isNull()).count()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Soluciones.\n",
        "Todos las soluciones las voy a buscar mediante objetos SQL de spark, pero tambien serian posibles mediante el objeto windows, en la solución a la primera pregunta pong un ejemplo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3xgOVBRZN6S"
      },
      "source": [
        "1. **¿Cuál es el país más “feliz” del 2021 según la data? (considerar que la columna “Ladder score” mayor número más feliz es el país)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El país más feliz del 2021 es: Finland \n"
          ]
        }
      ],
      "source": [
        "# Utilizar el objeto window seria una forma de conseguir los resultados, dejo aqui un ejemplo.\n",
        "from pyspark.sql import Window\n",
        "w = Window.orderBy(F.col(\"ladder\").desc())\n",
        "df_res_1= df_whr_c.filter(F.col(\"year\") == 2021).withColumn(\"drank\", F.rank().over(w)).filter(F.col(\"drank\") == 1)\n",
        "# df_res_1.show()\n",
        "# *************************************************************\n",
        "print(f\"El país más feliz del 2021 es: { df_res_1.select('country').first().country} \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utilizando SQL\n",
        "# creando la vista temporal\n",
        "df_whr_c.createOrReplaceTempView(\"temp_whrAll\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5JhXm4C3SwC",
        "outputId": "cf726164-23b4-4ab4-a0e3-969fc28cb140"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El país más feliz del 2021 es: Finland \n"
          ]
        }
      ],
      "source": [
        "# Solución SQL\n",
        "Qselect = \"select country, ladder from \" +\\\n",
        "     \" (select *, row_number() OVER (ORDER BY ladder DESC) as rn \" +\\\n",
        "     \" FROM temp_whrAll WHERE year = 2021) tmp where rn = 1\"\n",
        "\n",
        "df_res_1= spark.sql(Qselect)\n",
        "# df_res_1.show()\n",
        "print(f\"El país más feliz del 2021 es: { df_res_1.select('country').first().country} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl2fl91eMQIy"
      },
      "source": [
        "2. **¿Cuál es el país más “feliz” del 2021 por continente según la data?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8Es6551Lemv",
        "outputId": "7643cfab-0ae5-431f-b37d-7d4cb7ff4042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+-----------+------+\n",
            "|       region|    country|ladder|\n",
            "+-------------+-----------+------+\n",
            "|       Africa|  Mauritius| 6.049|\n",
            "|         Asia|     Israel| 7.157|\n",
            "|       Europe|    Finland| 7.842|\n",
            "|North America|     Canada| 7.103|\n",
            "|      Oceania|New Zealand| 7.277|\n",
            "|South America|    Uruguay| 6.431|\n",
            "+-------------+-----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Qselect = \"select region, country, ladder from \" +\\\n",
        "     \" (select *, row_number() OVER (PARTITION BY region ORDER BY ladder DESC) as rn \" +\\\n",
        "     \" FROM temp_whrAll WHERE year = 2021) tmp where rn = 1 order by region asc\"\n",
        "df_res_2= spark.sql(Qselect)\n",
        "df_res_2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q04O-zaflcPI"
      },
      "source": [
        "3. **¿Cuál es el país que más veces ocupó el primer lugar en todos los años?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCrzPba3lbhP",
        "outputId": "fa280e97-fae5-4b96-a4d2-03f89162fd57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Los paises que mas han ocupado el primer lugar son: Finland, Denmark\n"
          ]
        }
      ],
      "source": [
        "\n",
        "Qselect =  \"select country, repe from \" +\\\n",
        "      \"(select country, count(*) as repe from \" +\\\n",
        "     \" (select *, row_number() OVER (PARTITION BY year ORDER BY ladder DESC) as rn \" +\\\n",
        "     \" FROM temp_whrAll) tmp where rn = 1 group by country)\"+\\\n",
        "     \" WHERE repe = \"+\\\n",
        "      \"(select max(nveces) from (select count(*) as nveces from \" +\\\n",
        "     \" (select *, row_number() OVER (PARTITION BY year ORDER BY ladder DESC) as rn \" +\\\n",
        "     \" FROM temp_whrAll) tmp where rn = 1 group by country))\"\n",
        "\n",
        "df_res_3= spark.sql(Qselect)\n",
        "# df_res_3.show()\n",
        "# como pueden ser varios los registros, creo lista de valores del campo necesario\n",
        "countrys=df_res_3.select(df_res_3.country).rdd.flatMap(lambda x: x).collect()\n",
        "# *************************************************************\n",
        "print(f'Los paises que mas han ocupado el primer lugar son: {\", \".join(countrys)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5oJ4xnR5wr9"
      },
      "source": [
        "4. **¿Qué puesto de Felicidad tiene el país con mayor GDP del 2020?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deWo8qaj51ca",
        "outputId": "0eec539b-98b5-4a57-d1eb-636669e119b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El Pais con mejor ranking GDP del 2020 es Ireland y ocupa la posición 15 del ranking de paises más felices del 2021\n"
          ]
        }
      ],
      "source": [
        "Qselect = \"select country, rn from \" +\\\n",
        "     \" (select *, row_number() OVER (ORDER BY ladder DESC) as rn \" +\\\n",
        "     \" FROM temp_whrAll WHERE year = 2021) tmp \" +\\\n",
        "     \" where country = \" +\\\n",
        "     \" (select country from \" +\\\n",
        "     \" (select *, row_number() OVER (ORDER BY gdp DESC) as rn \" +\\\n",
        "     \" FROM temp_whrAll WHERE year = 2020) tmp where rn = 1)\"\n",
        "\n",
        "df_res_4= spark.sql(Qselect)\n",
        "# Aqui el resultado solo puede ser uno, otro metodo de acceso seria ir a la fila y sus valores.\n",
        "row_list = df_res_4.collect()\n",
        "print(f'El Pais con mejor ranking GDP del 2020 es {row_list[0].__getitem__(\"country\")} y ocupa la posición {row_list[0].__getitem__(\"rn\")} del ranking de paises más felices del 2021')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clVYR2bh51xr"
      },
      "source": [
        "5. **¿En que porcentaje a variado a nivel mundial el GDP promedio del 2020 respecto al 2021? ¿Aumentó o disminuyó?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_JHsKON54Ni",
        "outputId": "42f2bba2-fc18-4c6f-9b13-d6d5b5a88813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El el promedio de gdp anual disminuyó en un:  3.38 %\n"
          ]
        }
      ],
      "source": [
        "Qselect = \"select (select avg(gdp) from \" +\\\n",
        "     \" temp_whrAll WHERE year = 2021 and gdp is not null) as gdp2021, (select avg(gdp) from \" +\\\n",
        "     \" temp_whrAll WHERE year = 2020 and gdp is not null) as gdp2020 \"\n",
        "\n",
        "df_res_5= spark.sql(Qselect)\n",
        "# df_res_w.show()\n",
        "row_list = df_res_5.collect()\n",
        "promedio2021 = row_list[0].__getitem__(\"gdp2021\")\n",
        "promedio2020 = row_list[0].__getitem__(\"gdp2020\")\n",
        "if promedio2021 > promedio2020:\n",
        "  print(f'El el promedio de gdp anual aumentó en un:  {\"{:.2f}\".format((promedio2021-promedio2020)/promedio2021*100)} %')\n",
        "else:\n",
        "  print(f'El el promedio de gdp anual disminuyó en un:  {\"{:.2f}\".format(abs((promedio2021-promedio2020)/promedio2021*100))} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox9zxNQG54ob"
      },
      "source": [
        "6. **¿Cuál es el país con mayor expectativa de vide (“Healthy life expectancy at birth”)? Y ¿Cuánto tenia en ese indicador en el 2019?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pykBnB-p5697",
        "outputId": "938c1703-9212-45c5-b4ff-441c89a40ba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El Pais  con mayor expectativa de vida en 2021 es Iceland y en 2019 su esperanza de vida era de 0.983\n"
          ]
        }
      ],
      "source": [
        "Qselect = \"select country, healthy as healthy19 from \" +\\\n",
        "      \" temp_whrAll WHERE year = 2021 and country = \" +\\\n",
        "      \" (select country from \" +\\\n",
        "      \" (select *, row_number() OVER (ORDER BY healthy DESC) as rn \" +\\\n",
        "      \" FROM temp_whrAll WHERE year = 2021) tmp where rn = 1)\"\n",
        "\n",
        "df_res_6= spark.sql(Qselect)\n",
        "# df_res_6.show()\n",
        "# Aqui el resultado solo puede ser uno, otro metodo de acceso seria ir a la fila y sus valores. healthy\n",
        "row_list = df_res_6.collect()\n",
        "print(f'El Pais  con mayor expectativa de vida en 2021 es {row_list[0].__getitem__(\"country\")} y en 2019 su esperanza de vida era de {row_list[0].__getitem__(\"healthy19\")}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
